{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "100.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUCA7zxqq51m",
        "outputId": "5112329f-97f6-4098-cdb7-9242713ab8c4"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Input,Dropout\n",
        "import os\n",
        "!pip install keras\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# Directory with our training MR image\n",
        "\n",
        "\n",
        "data_all= os.path.join('/content/drive/MyDrive/chiken')##path to your photo\n",
        "#crate the image generator to (resize, normalize, filter and augmantation) images\n",
        "# All images will be rescaled by 1./255\n",
        "my_data = ImageDataGenerator(rescale=1./255,fill_mode='nearest')\n",
        "train_generator =my_data.flow_from_directory(data_all,target_size=(224,224),class_mode='binary',batch_size=5)\n",
        "################################################################################\n",
        "visible = Input(shape=(224, 224, 3))\n",
        "#########\n",
        "layer_in = Conv2D(64, (3,3), padding='same', activation='relu')(visible)\n",
        "layer_in = Conv2D(64, (3,3), padding='same', activation='relu')(layer_in)\n",
        "layer_in = MaxPooling2D((2,2), strides=(2,2))(layer_in)\n",
        "#######\n",
        "layer_in = Conv2D(128, (3,3), padding='same', activation='relu')(layer_in)\n",
        "layer_in = Conv2D(128, (3,3), padding='same', activation='relu')(layer_in)\n",
        "layer_in = MaxPooling2D((2,2), strides=(2,2))(layer_in)\n",
        "######\n",
        "layer_in = Conv2D(256, (3,3), padding='same', activation='relu')(layer_in)\n",
        "layer_in = Conv2D(256, (3,3), padding='same', activation='relu')(layer_in)\n",
        "layer_in = Conv2D(256, (3,3), padding='same', activation='relu')(layer_in)\n",
        "layer_in = Conv2D(256, (3,3), padding='same', activation='relu')(layer_in)\n",
        "layer_in = MaxPooling2D((2,2), strides=(2,2))(layer_in)\n",
        "\n",
        "layer_in = MaxPooling2D((2,2), strides=(2,2))(layer_in)\n",
        "layer_in = Flatten()(layer_in)\n",
        "layer_in = Dense(512, activation='relu' )(layer_in)\n",
        "layer_in = Dropout(0.5)(layer_in)\n",
        "layer_in = Dense(512, activation='relu' )(layer_in)\n",
        "layer_in = Dropout(0.5)(layer_in)\n",
        "layer_in = Dense(1, activation='sigmoid' )(layer_in)\n",
        "model = Model(inputs=visible, outputs=layer_in)\n",
        "################################################################################\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(0.0001), metrics=['accuracy'])\n",
        "history = model.fit(train_generator,steps_per_epoch=100,epochs=20)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.4.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras) (3.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras) (1.19.5)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras) (1.5.2)\n",
            "Found 68 images belonging to 2 classes.\n",
            "Epoch 1/20\n",
            "100/100 [==============================] - 23s 220ms/step - loss: 0.6937 - accuracy: 0.5117\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 0.6799 - accuracy: 0.5822\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 22s 218ms/step - loss: 0.6231 - accuracy: 0.6562\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 22s 218ms/step - loss: 0.5168 - accuracy: 0.7430\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 22s 220ms/step - loss: 0.4173 - accuracy: 0.8177\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 22s 216ms/step - loss: 0.2801 - accuracy: 0.9152\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 22s 221ms/step - loss: 0.1277 - accuracy: 0.9607\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3939 - accuracy: 0.8209\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.2541 - accuracy: 0.9457\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 0.0691 - accuracy: 0.9680\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 0.0483 - accuracy: 0.9809\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 22s 217ms/step - loss: 0.0568 - accuracy: 0.9858\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 22s 219ms/step - loss: 0.0706 - accuracy: 0.9732\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 21s 210ms/step - loss: 0.0402 - accuracy: 0.9879\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 21s 212ms/step - loss: 0.0054 - accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 21s 211ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 21s 211ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 21s 210ms/step - loss: 1.2845e-04 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 21s 212ms/step - loss: 7.9771e-05 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 21s 210ms/step - loss: 4.6921e-05 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}